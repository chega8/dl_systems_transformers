{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Code to set up the assignment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mcd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m/content/drive/MyDrive/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Code to set up the assignment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/\n",
    "\n",
    "!pip3 install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"pad_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import needle as ndl\n",
    "import needle.ops as ops\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, d_model = 100, 64\n",
    "val = np.random.random((1, T, d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.triu(-float(\"inf\")*torch.ones(T,T),1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19604483, 0.21950351, 0.31655932],\n",
       "       [0.35103041, 0.79442739, 0.14689571],\n",
       "       [0.62632848, 0.10272157, 0.26743422],\n",
       "       [0.82095482, 0.70563079, 0.49788598]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random((4, 3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4,), (4, 1))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(a, -1).shape, np.max(a, -1, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_tensor  = ndl.Tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(needle.Tensor(0.8209548),\n",
       " needle.Tensor([0.8209548  0.7944274  0.49788597]),\n",
       " needle.Tensor([0.3165593  0.7944274  0.62632847 0.8209548 ]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_tensor.maximum(), ndl_tensor.maximum(0), ndl_tensor.maximum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_grad: [1. 1. 1.], out_grad_shape: (3,) out_shape: (1, 3),  in_shape: (4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "needle.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_tensor = ndl.Tensor(a, requires_grad=True)\n",
    "b = ndl_tensor.maximum(0)\n",
    "out = b.sum()\n",
    "out.backward()\n",
    "ndl_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "needle.Tensor([0.8209548  0.7944274  0.49788597])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 2.0976e-17, 0.0000e+00],\n",
       "        [0.0000e+00, 3.7275e-17, 0.0000e+00],\n",
       "        [0.0000e+00, 1.8664e-17, 0.0000e+00],\n",
       "        [0.0000e+00, 3.4107e-17, 0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor = torch.tensor(a, requires_grad=True)\n",
    "torch_b = torch.softmax(torch_tensor, 0)\n",
    "out = torch_b.sum()\n",
    "out.backward()\n",
    "torch_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1794, 0.1889, 0.2503],\n",
       "        [0.2095, 0.3357, 0.2113],\n",
       "        [0.2759, 0.1681, 0.2383],\n",
       "        [0.3352, 0.3072, 0.3001]], dtype=torch.float64,\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, d = 100, 128\n",
    "attn = torch.nn.MultiheadAttention(d, 1, bias=False, batch_first=True)\n",
    "N = 10\n",
    "M = torch.triu(-float(\"inf\")*torch.ones(T,T),1)\n",
    "X = torch.randn(N, T, d)\n",
    "Y_, A_ = attn(X,X,X, attn_mask=M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_KQV = attn.in_proj_weight.detach().numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 128])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 384)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_KQV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_out = attn.out_proj.weight.detach().numpy().T\n",
    "W_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, d = 100, 128\n",
    "heads = 4\n",
    "N = 10\n",
    "M = torch.triu(-float(\"inf\") * torch.ones(T, T), 1).numpy()\n",
    "X = np.random.random((N, T, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_x = torch.tensor(X, dtype=torch.float32)\n",
    "torch_mask = torch.tensor(M, dtype=torch.float32)\n",
    "\n",
    "attn = torch.nn.MultiheadAttention(d, heads, bias=False, batch_first=True)\n",
    "Y_, A_ = attn(torch_x, torch_x, torch_x, attn_mask=torch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_kqv = ndl.nn.Parameter(attn.in_proj_weight.detach().numpy().T)\n",
    "w_out = ndl.nn.Parameter(attn.out_proj.weight.detach().numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 128)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x @ self.weight (10, 100, 384)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "split() got multiple values for argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [157], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m ndl_x \u001b[39m=\u001b[39m ndl\u001b[39m.\u001b[39mTensor(X)\n\u001b[1;32m      6\u001b[0m ndl_mask \u001b[39m=\u001b[39m ndl\u001b[39m.\u001b[39mTensor(M)\n\u001b[0;32m----> 8\u001b[0m Y, A \u001b[39m=\u001b[39m ndl_multihead_attention(ndl_x, ndl_mask)\n",
      "File \u001b[0;32m~/Desktop/dl_courses/cmu_dl_systems/dl_systems_transformers/./python/needle/nn.py:76\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/dl_courses/cmu_dl_systems/dl_systems_transformers/./python/needle/nn.py:828\u001b[0m, in \u001b[0;36mMultiHeadedAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    826\u001b[0m batch_size, seq_len, d_model \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[1;32m    827\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx @ self.weight \u001b[39m\u001b[39m{\u001b[39;00m(x \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight)\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 828\u001b[0m key, query, value \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49msplit(x \u001b[39m@\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39m3\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    829\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkey \u001b[39m\u001b[39m{\u001b[39;00m(key)\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    832\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__split_heads(key, batch_size, seq_len, d_model)\n",
      "\u001b[0;31mTypeError\u001b[0m: split() got multiple values for argument 'axis'"
     ]
    }
   ],
   "source": [
    "ndl_multihead_attention = ndl.nn.MultiHeadedAttention(heads, d)\n",
    "ndl_multihead_attention.weight = w_kqv\n",
    "ndl_multihead_attention.w_out = w_out\n",
    "\n",
    "ndl_x = ndl.Tensor(X)\n",
    "ndl_mask = ndl.Tensor(M)\n",
    "\n",
    "Y, A = ndl_multihead_attention(ndl_x, ndl_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "needle.Tensor([0. 1. 2. 3. 4. 5. 6. 7. 8.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl.Tensor(np.arange(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_split_dispatcher() missing 1 required positional argument: 'indices_or_sections'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [163], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ndl\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49msplit(ndl\u001b[39m.\u001b[39;49mTensor(np\u001b[39m.\u001b[39;49marange(\u001b[39m9\u001b[39;49m)), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/dl_courses/cmu_dl_systems/dl_systems_transformers/./python/needle/ops.py:518\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(a, axis):\n\u001b[0;32m--> 518\u001b[0m     \u001b[39mreturn\u001b[39;00m Split(axis)(a)\n",
      "File \u001b[0;32m~/Desktop/dl_courses/cmu_dl_systems/dl_systems_transformers/./python/needle/autograd.py:80\u001b[0m, in \u001b[0;36mTensorTupleOp.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m TensorTuple\u001b[39m.\u001b[39;49mmake_from_op(\u001b[39mself\u001b[39;49m, args)\n",
      "File \u001b[0;32m~/Desktop/dl_courses/cmu_dl_systems/dl_systems_transformers/./python/needle/autograd.py:151\u001b[0m, in \u001b[0;36mValue.make_from_op\u001b[0;34m(cls, op, inputs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m value\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    150\u001b[0m         \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m--> 151\u001b[0m     value\u001b[39m.\u001b[39;49mrealize_cached_data()\n\u001b[1;32m    152\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/Desktop/dl_courses/cmu_dl_systems/dl_systems_transformers/./python/needle/autograd.py:100\u001b[0m, in \u001b[0;36mValue.realize_cached_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n\u001b[1;32m     99\u001b[0m \u001b[39m# note: data implicitly calls realized cached data\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    101\u001b[0m     \u001b[39m*\u001b[39;49m[x\u001b[39m.\u001b[39;49mrealize_cached_data() \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs]\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n\u001b[1;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_data\n",
      "File \u001b[0;32m~/Desktop/dl_courses/cmu_dl_systems/dl_systems_transformers/./python/needle/ops.py:505\u001b[0m, in \u001b[0;36mSplit.compute\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, A):\n\u001b[1;32m    504\u001b[0m     \u001b[39m### BEGIN YOUR SOLUTION\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m array_api\u001b[39m.\u001b[39;49msplit(A, axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n",
      "File \u001b[0;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _split_dispatcher() missing 1 required positional argument: 'indices_or_sections'"
     ]
    }
   ],
   "source": [
    "ndl.ops.split(ndl.Tensor(np.arange(9)), axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('cmu_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "998dd1799808899da159c73324c38e2b8ac5d39cb24bcbc78a11f59c32aa7122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
